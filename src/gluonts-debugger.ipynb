{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import json\n",
    "import tempfile\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.dataset.loader import (\n",
    "    TrainDataLoader, ValidationDataLoader, InferenceDataLoader\n",
    ")\n",
    "from gluonts.dataset.repository.datasets import get_dataset\n",
    "from gluonts.model.deepar import DeepAREstimator\n",
    "from gluonts.trainer import Trainer\n",
    "from gluonts.support.util import get_hybrid_forward_input_names, HybridContext\n",
    "from gluonts.trainer import learning_rate_scheduler as lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.model.san import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_dataset('electricity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = SelfAttentionEstimator(\n",
    "    freq='h',\n",
    "    prediction_length=24,\n",
    "    context_length=168,\n",
    "    model_dim=64,\n",
    "    ffn_dim_multiplier=2,\n",
    "    num_heads=4,\n",
    "    num_layers=3,\n",
    "    num_outputs=3,\n",
    "    cardinalities=[370],\n",
    "    kernel_sizes=[5,9],\n",
    "    distance_encoding='dot',\n",
    "    use_feat_dynamic_cat=False,\n",
    "    use_feat_dynamic_real=False,\n",
    "    use_feat_static_cat=True,\n",
    "    use_feat_static_real=False,\n",
    "    trainer=Trainer(hybridize=False, epochs=1, learning_rate=1e-4)\n",
    ")\n",
    "transformation = estimator.create_transformation()\n",
    "training_data_loader = TrainDataLoader(\n",
    "    dataset=data.train,\n",
    "    transform=transformation,\n",
    "    batch_size=estimator.trainer.batch_size,\n",
    "    num_batches_per_epoch=estimator.trainer.num_batches_per_epoch,\n",
    "    ctx=estimator.trainer.ctx,\n",
    "    dtype=estimator.dtype,\n",
    "    num_workers=None,\n",
    "    num_prefetch=None,\n",
    "    shuffle_buffer_length=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with estimator.trainer.ctx:\n",
    "    train_net = estimator.create_training_network()\n",
    "train_net.initialize(ctx=estimator.trainer.ctx)\n",
    "input_names = get_hybrid_forward_input_names(train_net)\n",
    "with HybridContext(\n",
    "    net=train_net,\n",
    "    hybridize=False,\n",
    "    static_alloc=True,\n",
    "    static_shape=True,\n",
    "):\n",
    "    batch_size = training_data_loader.batch_size\n",
    "    lr_scheduler = lrs.MetricAttentiveScheduler(\n",
    "        objective=\"min\",\n",
    "        patience=estimator.trainer.patience,\n",
    "        decay_factor=estimator.trainer.learning_rate_decay_factor,\n",
    "        min_lr=estimator.trainer.minimum_learning_rate,\n",
    "    )\n",
    "    optimizer = mx.optimizer.Adam(\n",
    "        learning_rate=estimator.trainer.learning_rate,\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        wd=estimator.trainer.weight_decay,\n",
    "        clip_gradient=estimator.trainer.clip_gradient,\n",
    "    )\n",
    "    trainer = mx.gluon.Trainer(\n",
    "        train_net.collect_params(),\n",
    "        optimizer=optimizer,\n",
    "        kvstore=\"device\",\n",
    "    )\n",
    "    \n",
    "    for epoch_no in range(estimator.trainer.epochs):\n",
    "        if estimator.trainer.halt:\n",
    "            break\n",
    "        curr_lr = trainer.learning_rate\n",
    "        epoch_loss = mx.metric.Loss()\n",
    "        for batch_no, data_entry in enumerate(training_data_loader, 1):\n",
    "            if estimator.trainer.halt:\n",
    "                break\n",
    "            inputs = [data_entry[k] for k in input_names]\n",
    "            with mx.autograd.record():\n",
    "                output = train_net(*inputs)\n",
    "                if isinstance(output, (list, tuple)):\n",
    "                    loss = output[0]\n",
    "                else:\n",
    "                    loss = output\n",
    "                print(loss.asnumpy())\n",
    "            loss.backward()\n",
    "            trainer.step(batch_size)\n",
    "            epoch_loss.update(None, preds=loss)\n",
    "            lv = epoch_loss.get_name_value()[0][1]\n",
    "            if not np.isfinite(lv):\n",
    "                print(f\"Epoch{epoch_no} gave nan loss\")\n",
    "        should_continue = lr_scheduler.step(epoch_loss.get_name_value()[0][1]) \n",
    "        if not should_continue:\n",
    "            print(\"Stopping training\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('gluon': conda)",
   "language": "python",
   "name": "python_defaultSpec_1595204508022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}